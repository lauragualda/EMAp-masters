{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Recuperação de Informações\n",
    "\n",
    "## Lista de exercícios 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.corpus import machado, mac_morpho\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "\n",
    "import whoosh\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import *\n",
    "from whoosh import qparser\n",
    "from whoosh.qparser import QueryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Laura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package machado to\n",
      "[nltk_data]     C:\\Users\\Laura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('machado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos = []\n",
    "for p, d, f in os.walk(r'machado\\machado'):\n",
    "    print(p,d,f)\n",
    "    if f:\n",
    "        for fileid  in f:\n",
    "            if not fileid.endswith('.txt'):\n",
    "                continue\n",
    "            with open(os.path.join(p,fileid),'r') as g:\n",
    "                textos.append(g.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = [machado.raw(id) for id in machado.fileids()]\n",
    "len(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swu = stopwords.words('portuguese') + list (string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PortugueseStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1: Truncagem e revocação.\n",
    "\n",
    "Baseando-se no indice invertido construído na prática 1, Calcule a diferença de revocação com e sem a utilização de \"stemming\", ou truncagem na construção do índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o índice com stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textos1 = []\n",
    "for texto in textos:\n",
    "    tlimpo1 = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos1.append(tlimpo1)\n",
    "\n",
    "\n",
    "indice1 = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos1):\n",
    "    for term in t:\n",
    "        indice1[term].add(tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o índice sem stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos2 = []\n",
    "for texto in textos:\n",
    "    tlimpo2 = [token.lower() for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos2.append(tlimpo2)\n",
    "    \n",
    "\n",
    "indice2 = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos2):\n",
    "    for term in t:\n",
    "        indice2[term].add(tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 109, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 196, 198, 200, 202, 203, 204, 207, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245}\n"
     ]
    }
   ],
   "source": [
    "results1 = indice1[stemmer.stem('amor')]\n",
    "print (results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "R = len(results1)\n",
    "Ra = len(results1)\n",
    "\n",
    "print (Ra/R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 105, 106, 107, 109, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 128, 131, 132, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 172, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 196, 198, 200, 202, 203, 204, 207, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245}\n"
     ]
    }
   ],
   "source": [
    "results2 = indice2['amor']\n",
    "print (results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "R2 = len(results2)\n",
    "Ra2 = len(results2)\n",
    "\n",
    "print (Ra2/R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Como ambos os índices retornam todo o conjunto de informações relevantes (ocorrências da palavra \"amor\") disponível no universo, a revocação é de 100% com e sem truncagem. Como o índice com truncagem retorna outras variantes de \"amor\", a precisão com este índice seria menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Expansão de consultas\n",
    "Crie grupos de equivalência para alguns termos de busca e calcule a diferença em termos de revocação e, possivelmente precisão, na resposta a consultas expandidas e não expandidas. Dica: use tempos verbais, pluralização, sinônimos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grupo = ['amor', 'paixão', 'amar', 'amores', 'amavam', 'amaram', 'amam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o índice com stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 109, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 196, 198, 200, 202, 203, 204, 207, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 7, 110, 162, 205, 79, 97, 211, 133, 134, 150, 177, 215]\n"
     ]
    }
   ],
   "source": [
    "results1_grupo = []\n",
    "for k in grupo:\n",
    "    numero = indice1[stemmer.stem(k)]\n",
    "    for j in numero:\n",
    "        if j not in results1_grupo:\n",
    "            results1_grupo.append(j)\n",
    "\n",
    "print (results1_grupo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o índice sem stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 105, 106, 107, 109, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 128, 131, 132, 135, 136, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 172, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 196, 198, 200, 202, 203, 204, 207, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 7, 46, 110, 120, 162, 205, 79, 97, 211, 34, 104, 127, 176, 133, 177, 53]\n"
     ]
    }
   ],
   "source": [
    "results2_grupo = []\n",
    "for k in grupo:\n",
    "    numero = indice2[(k)]\n",
    "    for j in numero:\n",
    "        if j not in results2_grupo:\n",
    "            results2_grupo.append(j)\n",
    "\n",
    "print(results2_grupo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9601990049751243\n"
     ]
    }
   ],
   "source": [
    "# Revocação - sem stemmer\n",
    "R1 = len(results1)\n",
    "Ra1 = len(results1)\n",
    "\n",
    "print (Ra1/R1)\n",
    "\n",
    "# Precisão - sem stemmer\n",
    "A1 = len(results1)\n",
    "Ra = len(results2)\n",
    "\n",
    "print (Ra/A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Revocação - sem stemmer\n",
    "R2 = len(results2)\n",
    "Ra2 = len(results2)\n",
    "\n",
    "print (Ra2/R2)\n",
    "\n",
    "# Precisão - sem stemmer\n",
    "A2 = len(results2)\n",
    "Ra = len(results2)\n",
    "\n",
    "print (Ra/A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como ambos os índices retornam todo o conjunto de informações relevantes (ocorrências das palavras que fazem parte do grupo) disponível no universo, a revocação é de 100% com e sem truncagem. Como o índice com truncagem retorna outras variantes das palavras contidas no grupo, a precisão com este índice é menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Verificação ortográfica\n",
    "\n",
    "Implemente uma expansão de consulta por meio da correção ortográfica. Utilize o corretor ortográfico [Pyenchant](http://pythonhosted.org/pyenchant/) para fazer as correções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#d = enchant.Dict(\"pt_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Não deu certo devido à falta de compatibilidade do corretor com  a versão 64 bits do Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4: Consultas por frases\n",
    "Implemente um indice invertido que permita consulta por frases, conforme definido na aula 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textos_limpos = []\n",
    "for texto in textos:\n",
    "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos_limpos.append(tlimpo)\n",
    "    \n",
    "    \n",
    "indice4 = defaultdict(lambda:defaultdict(lambda:set([])))\n",
    "for tex_id, tex in enumerate(textos_limpos):\n",
    "    for tok_id,tok in enumerate(tex):\n",
    "        indice4[tok][tex_id].add(tok_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 132, 6, 139, 140, 17, 131, 148, 151, 24, 201, 155, 28, 29, 33, 27, 38, 39, 171, 46, 47, 51, 52, 182, 183, 184, 185, 186, 187, 188, 189, 190, 63, 193, 69, 12, 74, 80, 210, 35, 85, 86, 216, 58, 222, 224, 225, 231, 238, 157, 221, 119, 122, 191, 124])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice4[stemmer.stem(\"Fluminense\")].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 5, 13912}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice4[stemmer.stem(\"Fluminense\")][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando a função de busca por frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frase_tok = []    \n",
    "def busca(frase):\n",
    "    frase_tok = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(frase) if token not in swu]\n",
    " \n",
    "    matches = defaultdict(lambda:defaultdict(lambda:set([])))\n",
    "    for tok in frase_tok:\n",
    "        matches[tok] = indice4[tok]\n",
    "    \n",
    "    doc_pos = set(matches[frase_tok[0]])\n",
    "    for tok in frase_tok:\n",
    "        doc_pos = doc_pos.intersection(set(matches[tok]))\n",
    "        \n",
    "    resultado = set([]) \n",
    "    for doc in doc_pos:\n",
    "        for pos in matches[frase_tok[0]][doc]:\n",
    "            if all((pos + tokid + 1 in matches[tok][doc]) for tokid, tok in enumerate(frase_tok[1:len(frase_tok)])):\n",
    "                resultado.add(doc) \n",
    "                \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 4, 140, 21, 151, 29, 38, 39, 44, 59, 188, 63, 191, 193, 71, 72, 82, 87, 217, 90, 219, 92, 223, 226, 229, 230, 231, 104, 105, 235, 112, 116, 244, 120, 126}\n"
     ]
    }
   ],
   "source": [
    "print(busca(\"uma moça bonita\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{182, 183}\n"
     ]
    }
   ],
   "source": [
    "print(busca(\"história de uma moça rica\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{223}\n"
     ]
    }
   ],
   "source": [
    "print(busca(\"cada qual sabe amar a seu modo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(busca(\"o rio de janeiro continua lindo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5: Consulta híbrida.\n",
    "\n",
    "Modifique a solução acima para permitir respostas alternativas caso a frase não retorne resultados. Por exemplo, retornar, documentos que contenham parte da frase, ou uma busca booleana simples combinando as palavras da frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = Schema(content=TEXT(phrase=True, stored=True))\n",
    "\n",
    "if os.path.exists('indexdir'):\n",
    "    ix = open_dir('indexdir')\n",
    "else:\n",
    "    os.mkdir('indexdir')\n",
    "    ix = create_in(\"indexdir\", schema)\n",
    "    writer = ix.writer()\n",
    "    for txt in textos:\n",
    "        writer.add_document(content=txt)\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "searcher = ix.searcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Criando a função alternativa de busca por frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frase_tok = []    \n",
    "def busca_alt(frase):\n",
    "    frase_tok = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(frase) if token not in swu]\n",
    " \n",
    "    matches = defaultdict(lambda:defaultdict(lambda:set([])))\n",
    "    for tok in frase_tok:\n",
    "        matches[tok] = indice4[tok]\n",
    "    \n",
    "    doc_pos = set(matches[frase_tok[0]])\n",
    "    for tok in frase_tok:\n",
    "        doc_pos = doc_pos.intersection(set(matches[tok]))\n",
    "        \n",
    "    resultado = set([]) \n",
    "    \n",
    "    for doc in doc_pos:\n",
    "        for pos in matches[frase_tok[0]][doc]:\n",
    "            if all((pos + tokid + 1 in matches[tok][doc]) for tokid, tok in enumerate(frase_tok[1:len(frase_tok)])):\n",
    "                resultado.add(doc)\n",
    "                \n",
    "    if resultado == set([]):\n",
    "        searcher = ix.searcher()\n",
    "        query = QueryParser(\"content\", ix.schema).parse(frase)\n",
    "        resultado_alt = searcher.search(query)\n",
    "        return resultado_alt.docs()\n",
    "    else:\n",
    "        return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print (busca(\"o rio de janeiro continua lindo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 193, 2, 98, 4, 224, 227, 228, 229, 230, 139, 244, 219, 221, 222, 191}\n"
     ]
    }
   ],
   "source": [
    "print (busca_alt(\"o rio de janeiro continua lindo\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
